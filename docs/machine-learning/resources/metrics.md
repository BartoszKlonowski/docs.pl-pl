---
title: Metryki strukturze ML.NET
description: Omówienie metryk, które są używane do oceny wydajności na model w strukturze ML.NET
ms.date: 04/29/2019
author: natke
ms.openlocfilehash: ca5bc795a9d9ff4fe1035d2ec0672f1f7c21fe0b
ms.sourcegitcommit: bab17fd81bab7886449217356084bf4881d6e7c8
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 06/26/2019
ms.locfileid: "67397604"
---
# <a name="model-evaluation-metrics-in-mlnet"></a><span data-ttu-id="17133-103">Metryki oceny model w strukturze ML.NET</span><span class="sxs-lookup"><span data-stu-id="17133-103">Model evaluation metrics in ML.NET</span></span>

## <a name="metrics-for-binary-classification"></a><span data-ttu-id="17133-104">Metryki dla klasyfikacji binarnej</span><span class="sxs-lookup"><span data-stu-id="17133-104">Metrics for Binary Classification</span></span>

| <span data-ttu-id="17133-105">Metryki</span><span class="sxs-lookup"><span data-stu-id="17133-105">Metrics</span></span>   |      <span data-ttu-id="17133-106">Opis</span><span class="sxs-lookup"><span data-stu-id="17133-106">Description</span></span>      |  <span data-ttu-id="17133-107">Szukać</span><span class="sxs-lookup"><span data-stu-id="17133-107">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="17133-108">**Accuracy**</span><span class="sxs-lookup"><span data-stu-id="17133-108">**Accuracy**</span></span> |  <span data-ttu-id="17133-109">[Dokładność](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) to poprawne prognoz z zestawem danych testowych.</span><span class="sxs-lookup"><span data-stu-id="17133-109">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="17133-110">To stosunek liczby poprawne prognoz całkowitą liczbę próbek danych wejściowych.</span><span class="sxs-lookup"><span data-stu-id="17133-110">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="17133-111">Działa to dobrze tylko w przypadku podobną liczbę próbek należących do każdej klasy.</span><span class="sxs-lookup"><span data-stu-id="17133-111">It works well only if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="17133-112">**Bliżej 1,00, tym lepsze**.</span><span class="sxs-lookup"><span data-stu-id="17133-112">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="17133-113">Ale 1,00 dokładnie oznacza problem związany (często: Etykieta docelowa wycieku nadmiernie dopasowane i testowania przy użyciu danych szkoleniowych).</span><span class="sxs-lookup"><span data-stu-id="17133-113">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="17133-114">Gdy jest dane testowe niezrównoważone (gdzie większość wystąpień należą do jednej z klas), zestaw danych jest bardzo mały lub wyniki podejście 0,00 lub 1,00, a dokładność tak naprawdę nie odzwierciedla skuteczność klasyfikatora należy sprawdzić dodatkowe metryki.</span><span class="sxs-lookup"><span data-stu-id="17133-114">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is very small, or scores approach 0.00 or 1.00, then accuracy doesn’t really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="17133-115">**AUC**</span><span class="sxs-lookup"><span data-stu-id="17133-115">**AUC**</span></span> |    <span data-ttu-id="17133-116">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) lub *powierzchni pod krzywą*: Jest to pomiar obszar pod krzywą utworzone przez sprawdzaniu true na dodatnich a fałszywie dodatnich.</span><span class="sxs-lookup"><span data-stu-id="17133-116">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve*: This is measuring the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="17133-117">**Bliżej 1,00, tym lepsze**.</span><span class="sxs-lookup"><span data-stu-id="17133-117">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="17133-118">Powinien być większy niż 0,50 modelu do przyjęcia; Optymalizacja jest model przy użyciu AUC 0,50 lub mniej.</span><span class="sxs-lookup"><span data-stu-id="17133-118">It should be greater than 0.50 for a model to be acceptable; a model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="17133-119">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="17133-119">**AUCPR**</span></span> | <span data-ttu-id="17133-120">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) lub *powierzchni pod krzywą krzywych Precision-Recall*: Przydatne pomiar sukcesu prognozowania, gdy klasy są bardzo imbalanced (wysoce niesymetryczne zbiory danych).</span><span class="sxs-lookup"><span data-stu-id="17133-120">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are very imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="17133-121">**Bliżej 1,00, tym lepsze**.</span><span class="sxs-lookup"><span data-stu-id="17133-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="17133-122">Wysoka wyniki zbliżone do wartości 1.00 show, że klasyfikatora jest zwracanie dokładne wyniki (dużej dokładności), a także zwracanie większość wszystkich wyników pozytywnych (wycofaniu wysoki).</span><span class="sxs-lookup"><span data-stu-id="17133-122">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="17133-123">**Wynik F1**</span><span class="sxs-lookup"><span data-stu-id="17133-123">**F1-score**</span></span> | <span data-ttu-id="17133-124">[Wynik F1](https://en.wikipedia.org/wiki/F1_score) znany także jako *równoważenia wynik F lub F-miary*.</span><span class="sxs-lookup"><span data-stu-id="17133-124">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="17133-125">Jest harmoniczna dokładności i odwołania.</span><span class="sxs-lookup"><span data-stu-id="17133-125">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="17133-126">Wynik F1 jest przydatne, gdy chcesz wyszukać równowagi między dokładności i odwołania.</span><span class="sxs-lookup"><span data-stu-id="17133-126">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="17133-127">**Bliżej 1,00, tym lepsze**.</span><span class="sxs-lookup"><span data-stu-id="17133-127">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="17133-128">Wynik F1 osiągnie swojej wartości najlepsze 1.00 i najgorszego wyniku w 0,00.</span><span class="sxs-lookup"><span data-stu-id="17133-128">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="17133-129">Informuje, jak dokładne jest klasyfikatora.</span><span class="sxs-lookup"><span data-stu-id="17133-129">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="17133-130">Aby uzyskać dodatkowe szczegóły dotyczące klasyfikacji binarnej metryki, przeczytaj następujące artykuły:</span><span class="sxs-lookup"><span data-stu-id="17133-130">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="17133-131">Dokładność, dokładności, odwołań lub F1?</span><span class="sxs-lookup"><span data-stu-id="17133-131">Accuracy, Precision, Recall or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="17133-132">Binarny klasy metryki klasyfikacji</span><span class="sxs-lookup"><span data-stu-id="17133-132">Binary Classification Metrics class</span></span>](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [<span data-ttu-id="17133-133">Relacja między Precision-Recall oraz ROC krzywych</span><span class="sxs-lookup"><span data-stu-id="17133-133">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="metrics-for-multi-class-classification"></a><span data-ttu-id="17133-134">Metryki dla klasyfikacji wieloklasowej</span><span class="sxs-lookup"><span data-stu-id="17133-134">Metrics for Multi-class Classification</span></span>

| <span data-ttu-id="17133-135">Metryki</span><span class="sxs-lookup"><span data-stu-id="17133-135">Metrics</span></span>   |      <span data-ttu-id="17133-136">Opis</span><span class="sxs-lookup"><span data-stu-id="17133-136">Description</span></span>      |  <span data-ttu-id="17133-137">Szukać</span><span class="sxs-lookup"><span data-stu-id="17133-137">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="17133-138">**Micro dokładności**</span><span class="sxs-lookup"><span data-stu-id="17133-138">**Micro-Accuracy**</span></span> |  <span data-ttu-id="17133-139">[Średnia Micro dokładność](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) agreguje wkładów wszystkich klas do obliczenia średniej metryki.</span><span class="sxs-lookup"><span data-stu-id="17133-139">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="17133-140">Jest to ułamek wystąpień poprawnie przewidzieć.</span><span class="sxs-lookup"><span data-stu-id="17133-140">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="17133-141">Średnia micro nie przyjmuje członkostwa klasy pod uwagę.</span><span class="sxs-lookup"><span data-stu-id="17133-141">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="17133-142">Po prostu każdej pary przykładową klasę przyczynia się jednakowo do metryki dokładności.</span><span class="sxs-lookup"><span data-stu-id="17133-142">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="17133-143">**Bliżej 1,00, tym lepsze**.</span><span class="sxs-lookup"><span data-stu-id="17133-143">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="17133-144">W zadaniu klasyfikacji wieloklasowej micro dokładności jest za pośrednictwem makra dokładność Jeśli podejrzewasz, że może to być nierównowagi klasy (tj.)</span><span class="sxs-lookup"><span data-stu-id="17133-144">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="17133-145">Możesz mieć wiele więcej przykładów dotyczących jednej klasy niż inne klasy).</span><span class="sxs-lookup"><span data-stu-id="17133-145">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="17133-146">**Dokładność — makro**</span><span class="sxs-lookup"><span data-stu-id="17133-146">**Macro-Accuracy**</span></span> | <span data-ttu-id="17133-147">[Średnia — makro dokładność](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) jest średnia dokładności na poziomie klasy.</span><span class="sxs-lookup"><span data-stu-id="17133-147">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="17133-148">Dokładność dla każdej klasy jest kolumną obliczaną, a dokładność — makro jest średnią te dokładności.</span><span class="sxs-lookup"><span data-stu-id="17133-148">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="17133-149">Zasadniczo każda klasa przyczynia się jednakowo do metryki dokładności.</span><span class="sxs-lookup"><span data-stu-id="17133-149">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="17133-150">Moduł klasy są podane weight równe jako większych klas.</span><span class="sxs-lookup"><span data-stu-id="17133-150">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="17133-151">Metryki średnia — makro daje tymi samymi wagami do każdej klasy, niezależnie od tego, ile wystąpień przy jego użyciu zawiera klasę zestawu danych.</span><span class="sxs-lookup"><span data-stu-id="17133-151">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="17133-152">**Bliżej 1,00, tym lepsze**.</span><span class="sxs-lookup"><span data-stu-id="17133-152">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="17133-153">Ją oblicza metryki niezależnie dla każdej klasy, a następnie pobiera średnia (dlatego traktowanie wszystkich klas równie)</span><span class="sxs-lookup"><span data-stu-id="17133-153">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="17133-154">**Log-loss**</span><span class="sxs-lookup"><span data-stu-id="17133-154">**Log-loss**</span></span>| <span data-ttu-id="17133-155">[Logarytmicznej utraty](http://wiki.fast.ai/index.php/Log_Loss) mierzy wydajność model klasyfikacji, w których dane wejściowe prognozy są wartość prawdopodobieństwa między 0,00 i 1,00.</span><span class="sxs-lookup"><span data-stu-id="17133-155">[Logarithmic loss](http://wiki.fast.ai/index.php/Log_Loss) measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="17133-156">Utraty dziennika zwiększa prawdopodobieństwo, że dostęp do przewidywanych diverges od rzeczywistej etykiety.</span><span class="sxs-lookup"><span data-stu-id="17133-156">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="17133-157">**Bliżej 0,00, tym lepsze**.</span><span class="sxs-lookup"><span data-stu-id="17133-157">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="17133-158">Idealny model musi utraty dziennika 0,00.</span><span class="sxs-lookup"><span data-stu-id="17133-158">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="17133-159">Celem naszych modeli uczenia maszynowego jest zminimalizowanie tę wartość.</span><span class="sxs-lookup"><span data-stu-id="17133-159">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="17133-160">**Zmniejszenie dziennika strat**</span><span class="sxs-lookup"><span data-stu-id="17133-160">**Log-Loss Reduction**</span></span> | <span data-ttu-id="17133-161">[Zmniejszenie logarytmicznej strat](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) może być interpretowana jako zalet klasyfikatora względem prognoz losowych.</span><span class="sxs-lookup"><span data-stu-id="17133-161">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="17133-162">**W zakresie od -inf i 1,00, gdzie 1,00 to doskonałe prognoz, a 0,00 wskazuje średnią prognozy**.</span><span class="sxs-lookup"><span data-stu-id="17133-162">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="17133-163">Na przykład jeśli wartość jest równa 0.20 lub nowszej, jego mogą być interpretowane jako "prawdopodobieństwo, że prawidłowe przewidywanie wynosi 20% lepsze niż losowe zgadywania"</span><span class="sxs-lookup"><span data-stu-id="17133-163">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="17133-164">Dokładność Micro ogólnie jest lepiej wyrównane z potrzebami biznesowymi prognoz uczenia Maszynowego.</span><span class="sxs-lookup"><span data-stu-id="17133-164">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="17133-165">Chcącym jednej metryki dotyczące wybierania jakość zadanie klasyfikacji wieloklasowej zwykle należy micro dokładności.</span><span class="sxs-lookup"><span data-stu-id="17133-165">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="17133-166">Przykład zadanie klasyfikacji bilet pomocy technicznej: (mapuje przychodzące bilety do obsługi zespołów)</span><span class="sxs-lookup"><span data-stu-id="17133-166">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="17133-167">Dokładność Micro — jak często bilet usługi w przychodzących Pobierz sklasyfikowane na odpowiedni zespół?</span><span class="sxs-lookup"><span data-stu-id="17133-167">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="17133-168">Dokładność — makro — średnia zespołu, jak często jest bilet usługi w przychodzących poprawne dla swojego zespołu?</span><span class="sxs-lookup"><span data-stu-id="17133-168">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="17133-169">Dokładność — makro overweights małych zespołów, w tym przykładzie; małych zespołów, które pobiera tylko 10 bilety na rok traktowany jak duży zespół o 10k biletów na rok.</span><span class="sxs-lookup"><span data-stu-id="17133-169">Macro-accuracy overweights small teams in this example; a small team which gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="17133-170">Dokładność Micro w tym przypadku jest odwrotnie skorelowana lepiej z potrzeb biznesowych dla "czasu/zarobków można firmy Zapisz dzięki automatyzacji procesu routingu Moje biletu".</span><span class="sxs-lookup"><span data-stu-id="17133-170">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="17133-171">Aby uzyskać dodatkowe szczegóły dotyczące klasyfikacji wieloklasowej metryki, przeczytaj następujące artykuły:</span><span class="sxs-lookup"><span data-stu-id="17133-171">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="17133-172">Średnia Micro i makra, które dokładności, odwołania i ocena F</span><span class="sxs-lookup"><span data-stu-id="17133-172">Micro- and Macro-average of Precision, Recall and F-Score</span></span>](http://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="17133-173">Klasyfikacji wieloklasowej Imbalanced zestawu danych</span><span class="sxs-lookup"><span data-stu-id="17133-173">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="metrics-for-regression"></a><span data-ttu-id="17133-174">Metryki dotyczące regresji</span><span class="sxs-lookup"><span data-stu-id="17133-174">Metrics for Regression</span></span>

| <span data-ttu-id="17133-175">Metryki</span><span class="sxs-lookup"><span data-stu-id="17133-175">Metrics</span></span>   |      <span data-ttu-id="17133-176">Opis</span><span class="sxs-lookup"><span data-stu-id="17133-176">Description</span></span>      |  <span data-ttu-id="17133-177">Szukać</span><span class="sxs-lookup"><span data-stu-id="17133-177">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="17133-178">**R-kwadrat**</span><span class="sxs-lookup"><span data-stu-id="17133-178">**R-Squared**</span></span> |  <span data-ttu-id="17133-179">[R-kwadrat (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), lub *determinacji* reprezentuje możliwości predykcyjnego modelu jako wartość z zakresu od -inf 1,00.</span><span class="sxs-lookup"><span data-stu-id="17133-179">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="17133-180">1,00 oznacza, że istnieje dokładne dopasowanie i dopasowania mogą być arbitrarly niską wyniki. może być ujemna.</span><span class="sxs-lookup"><span data-stu-id="17133-180">1.00 means there is a perfect fit, and the fit can be arbitrarly poor so the scores can be negative.</span></span> <span data-ttu-id="17133-181">Ocena oznacza 0,00 modelu jest zgadywania oczekiwanej wartości dla etykiety.</span><span class="sxs-lookup"><span data-stu-id="17133-181">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="17133-182">R2 środków, jak blisko wartości danych rzeczywistych testów są przewidywane wartości.</span><span class="sxs-lookup"><span data-stu-id="17133-182">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="17133-183">**Bliżej 1,00, lepszą jakość**.</span><span class="sxs-lookup"><span data-stu-id="17133-183">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="17133-184">Jednak czasami niskich wartości R-kwadrat (na przykład 0,50) może być całkowicie normalne lub wystarczające dla danego scenariusza i wysokich wartości R-kwadrat nie zawsze są dobre i się podejrzane.</span><span class="sxs-lookup"><span data-stu-id="17133-184">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="17133-185">**Utrata bezwzględne**</span><span class="sxs-lookup"><span data-stu-id="17133-185">**Absolute-loss**</span></span> |  <span data-ttu-id="17133-186">[Bezwzględna utraty](https://en.wikipedia.org/wiki/Mean_absolute_error) lub *średni bezwzględny błąd (dostosowania)* mierzy się, jak blisko prognozy są rzeczywiste wyniki.</span><span class="sxs-lookup"><span data-stu-id="17133-186">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="17133-187">Jest średnią wszystkich błędów modelu, gdzie błąd modelu jest bezwzględny odległość między wartości prognozowanej etykiety i wartość prawidłowa etykieta.</span><span class="sxs-lookup"><span data-stu-id="17133-187">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="17133-188">Ten błąd prognozowania jest obliczana dla każdego rekordu testowego zestawu danych.</span><span class="sxs-lookup"><span data-stu-id="17133-188">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="17133-189">Na koniec średnią wartość jest obliczana dla wszystkich zarejestrowanych bezwzględnych błędów.</span><span class="sxs-lookup"><span data-stu-id="17133-189">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="17133-190">**Bliżej 0,00, lepszą jakość.**</span><span class="sxs-lookup"><span data-stu-id="17133-190">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="17133-191">Należy pamiętać, że średni bezwzględny błąd używa tej samej skali z danymi, mierzony (nie jest znormalizowana do określonego zakresu).</span><span class="sxs-lookup"><span data-stu-id="17133-191">Note that the mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="17133-192">Do dokonywania porównań między modelami dla tego samego zestawu danych lub zestaw danych o rozkład wartości podobne etykietę tylko można utraty bezwzględną, utraty Squared i utratę usługi RMS.</span><span class="sxs-lookup"><span data-stu-id="17133-192">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a smilar label value distribution.</span></span> |
| <span data-ttu-id="17133-193">**Squared-loss**</span><span class="sxs-lookup"><span data-stu-id="17133-193">**Squared-loss**</span></span> |  <span data-ttu-id="17133-194">[Utrata Squared](https://en.wikipedia.org/wiki/Mean_squared_error) lub *oznacza kwadrat błędu (MSE)* , nazywane również *oznacza kwadrat odchylenia (MSD)* , informujący o tym, jak blisko linii regresji ma zestaw wartości danych testowych.</span><span class="sxs-lookup"><span data-stu-id="17133-194">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values.</span></span> <span data-ttu-id="17133-195">Odbywa się to przez pobranie odległości od punktów do regresji (odległości te są błędy E) i squaring je.</span><span class="sxs-lookup"><span data-stu-id="17133-195">It does this by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="17133-196">Squaring daje więcej wagę do większych różnice.</span><span class="sxs-lookup"><span data-stu-id="17133-196">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="17133-197">Zawsze jest ujemna, i **wartości bliższe 0,00 są lepsze**.</span><span class="sxs-lookup"><span data-stu-id="17133-197">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="17133-198">W zależności od danych może być niemożliwe uzyskać bardzo małych wartości średniej kwadratów błędów.</span><span class="sxs-lookup"><span data-stu-id="17133-198">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="17133-199">**RMS-loss**</span><span class="sxs-lookup"><span data-stu-id="17133-199">**RMS-loss**</span></span> |  <span data-ttu-id="17133-200">[RMS utraty](https://en.wikipedia.org/wiki/Root-mean-square_deviation) lub *głównego oznacza kwadrat błąd (RMSE)* (nazywane również *odchylenie skuteczną, RMSD*), faktycznie mierzy różnią się przewidzieć przez model wartości i wartości obserwowane ze środowiska, które są w modelu.</span><span class="sxs-lookup"><span data-stu-id="17133-200">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values actually observed from the environment that is being modeled.</span></span> <span data-ttu-id="17133-201">Utrata usługi RMS jest pierwiastek kwadratowy utraty Squared i ma te same jednostki jako etykieta, podobnie jak utrata bezwzględnymi, chociaż przyznawania ważniejsze większych różnice.</span><span class="sxs-lookup"><span data-stu-id="17133-201">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the abolute-loss though giving more weight to larger diferences.</span></span> <span data-ttu-id="17133-202">Błąd głównego średniej kwadratowej jest najczęściej używany w klimatologia, prognozowania i analizę regresji do zweryfikować eksperymentalne wyniki.</span><span class="sxs-lookup"><span data-stu-id="17133-202">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="17133-203">Zawsze jest ujemna, i **wartości bliższe 0,00 są lepsze**.</span><span class="sxs-lookup"><span data-stu-id="17133-203">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="17133-204">RMSD jest miarą dokładności, aby porównać prognozowania błędy różne modele dla określonego zestawu danych i nie między zestawami danych, ponieważ jest zależna od skali.</span><span class="sxs-lookup"><span data-stu-id="17133-204">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="17133-205">Aby uzyskać dodatkowe szczegóły dotyczące regresji metryki, przeczytaj następujące artykuły:</span><span class="sxs-lookup"><span data-stu-id="17133-205">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="17133-206">Analizę regresji: Jak interpretować R-kwadrat i ocenić zgodność Dopasuj?</span><span class="sxs-lookup"><span data-stu-id="17133-206">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="17133-207">Jak interpretować R-kwadrat w analizę regresji</span><span class="sxs-lookup"><span data-stu-id="17133-207">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="17133-208">Definicja języka R-kwadrat</span><span class="sxs-lookup"><span data-stu-id="17133-208">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="17133-209">Średni kwadrat definicji błędu</span><span class="sxs-lookup"><span data-stu-id="17133-209">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="17133-210">Jakie są oznacza błąd kwadrat i błąd oznacza kwadrat główny?</span><span class="sxs-lookup"><span data-stu-id="17133-210">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)

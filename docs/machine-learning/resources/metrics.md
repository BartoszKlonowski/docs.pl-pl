---
title: ML.NET metryki
description: Zrozumienie metryk, które są używane do oceny wydajności modelu ML.NET
ms.date: 12/17/2019
ms.openlocfilehash: 8e823fd8cc344c1b8e0ecd709b527137368cbfa0
ms.sourcegitcommit: 7588136e355e10cbc2582f389c90c127363c02a5
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 03/15/2020
ms.locfileid: "79399218"
---
# <a name="evaluate-your-mlnet-model-with-metrics"></a><span data-ttu-id="ae26a-103">Oceń swój model ML.NET za pomocą metryk</span><span class="sxs-lookup"><span data-stu-id="ae26a-103">Evaluate your ML.NET model with metrics</span></span>

<span data-ttu-id="ae26a-104">Zapoznaj się z metrykami używanymi do oceny modelu ML.NET.</span><span class="sxs-lookup"><span data-stu-id="ae26a-104">Understand the metrics used to evaluate an ML.NET model.</span></span>

<span data-ttu-id="ae26a-105">Metryki oceny są specyficzne dla typu zadania uczenia maszynowego, które wykonuje model.</span><span class="sxs-lookup"><span data-stu-id="ae26a-105">Evaluation metrics are specific to the type of machine learning task that a model performs.</span></span>

<span data-ttu-id="ae26a-106">Na przykład dla zadania klasyfikacji model jest oceniany przez pomiar, jak dobrze przewidywana kategoria pasuje do rzeczywistej kategorii.</span><span class="sxs-lookup"><span data-stu-id="ae26a-106">For example, for the classification task, the model is evaluated by measuring how well a predicted category matches the actual category.</span></span> <span data-ttu-id="ae26a-107">A w przypadku klastrowania ocena opiera się na tym, jak blisko są elementy klastrowane do siebie i jak wiele jest separacji między klastrami.</span><span class="sxs-lookup"><span data-stu-id="ae26a-107">And for clustering, evaluation is based on how close clustered items are to each other, and how much separation there is between the clusters.</span></span>

## <a name="evaluation-metrics-for-binary-classification"></a><span data-ttu-id="ae26a-108">Metryki oceny dla klasyfikacji binarnej</span><span class="sxs-lookup"><span data-stu-id="ae26a-108">Evaluation metrics for Binary Classification</span></span>

| <span data-ttu-id="ae26a-109">Metryki</span><span class="sxs-lookup"><span data-stu-id="ae26a-109">Metrics</span></span>   |      <span data-ttu-id="ae26a-110">Opis</span><span class="sxs-lookup"><span data-stu-id="ae26a-110">Description</span></span>      |  <span data-ttu-id="ae26a-111">Szukać</span><span class="sxs-lookup"><span data-stu-id="ae26a-111">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="ae26a-112">**Dokładność**</span><span class="sxs-lookup"><span data-stu-id="ae26a-112">**Accuracy**</span></span> |  <span data-ttu-id="ae26a-113">[Dokładność](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) jest proporcją poprawnych prognoz z zestawem danych testowych.</span><span class="sxs-lookup"><span data-stu-id="ae26a-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="ae26a-114">Jest to stosunek liczby prawidłowych prognoz do całkowitej liczby próbek wejściowych.</span><span class="sxs-lookup"><span data-stu-id="ae26a-114">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="ae26a-115">Działa dobrze, jeśli istnieje podobna liczba próbek należących do każdej klasy.</span><span class="sxs-lookup"><span data-stu-id="ae26a-115">It works well if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="ae26a-116">**Im bliżej 1.00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="ae26a-116">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="ae26a-117">Ale dokładnie 1,00 wskazuje na problem (często: wyciek etykiety/celu, nadmierne dopasowanie lub testowanie danych szkoleniowych).</span><span class="sxs-lookup"><span data-stu-id="ae26a-117">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="ae26a-118">Gdy dane testowe są niezrównoważone (gdzie większość wystąpień należą do jednej z klas), zestaw danych jest mały lub wyniki podejście 0,00 lub 1,00, a następnie dokładność naprawdę nie przechwytywać skuteczność klasyfikatora i trzeba sprawdzić dodatkowe metryki.</span><span class="sxs-lookup"><span data-stu-id="ae26a-118">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is small, or scores approach 0.00 or 1.00, then accuracy doesn’t really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="ae26a-119">**Auc**</span><span class="sxs-lookup"><span data-stu-id="ae26a-119">**AUC**</span></span> |    <span data-ttu-id="ae26a-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) lub *Obszar pod krzywą* mierzy obszar pod krzywą, utworzony przez zamiatanie rzeczywistej dodatniej stopy w porównaniu z fałszywie dodatnim wskaźnikiem.</span><span class="sxs-lookup"><span data-stu-id="ae26a-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve* measures the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="ae26a-121">**Im bliżej 1.00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="ae26a-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="ae26a-122">Dla akceptowalnego modelu model powinien być większy niż 0,50.</span><span class="sxs-lookup"><span data-stu-id="ae26a-122">It should be greater than 0.50 for a model to be acceptable.</span></span> <span data-ttu-id="ae26a-123">Model z AUC 0,50 lub mniej jest bezwartościowy.</span><span class="sxs-lookup"><span data-stu-id="ae26a-123">A model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="ae26a-124">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="ae26a-124">**AUCPR**</span></span> | <span data-ttu-id="ae26a-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) lub *Obszar pod krzywą krzywej precyzyjnego przywołania*: Przydatna miara powodzenia przewidywania, gdy klasy są nierówne (wysoce skośne zestawy danych).</span><span class="sxs-lookup"><span data-stu-id="ae26a-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="ae26a-126">**Im bliżej 1.00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="ae26a-126">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="ae26a-127">Wysokie wyniki blisko 1,00 pokazują, że klasyfikator zwraca dokładne wyniki (wysoka precyzja), a także zwraca większość wszystkich pozytywnych wyników (wysokie wycofanie).</span><span class="sxs-lookup"><span data-stu-id="ae26a-127">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="ae26a-128">**Wynik F1**</span><span class="sxs-lookup"><span data-stu-id="ae26a-128">**F1-score**</span></span> | <span data-ttu-id="ae26a-129">[F1 wynik](https://en.wikipedia.org/wiki/F1_score) znany również jako *zrównoważony F-score lub F-measure*.</span><span class="sxs-lookup"><span data-stu-id="ae26a-129">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="ae26a-130">Jest to harmoniczny oznacza precyzji i przypomnieć.</span><span class="sxs-lookup"><span data-stu-id="ae26a-130">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="ae26a-131">Wynik F1 jest pomocny, gdy chcesz uzyskać równowagę między precyzją a wycofaniem.</span><span class="sxs-lookup"><span data-stu-id="ae26a-131">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="ae26a-132">**Im bliżej 1.00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="ae26a-132">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="ae26a-133">Wynik F1 osiąga najlepszą wartość na 1,00 i najgorszy wynik na 0,00.</span><span class="sxs-lookup"><span data-stu-id="ae26a-133">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="ae26a-134">Informuje, jak precyzyjny jest twój klasyfikator.</span><span class="sxs-lookup"><span data-stu-id="ae26a-134">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="ae26a-135">Aby uzyskać więcej informacji na temat metryki klasyfikacji binarnej przeczytać następujące artykuły:</span><span class="sxs-lookup"><span data-stu-id="ae26a-135">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="ae26a-136">Dokładność, precyzja, wycofanie lub F1?</span><span class="sxs-lookup"><span data-stu-id="ae26a-136">Accuracy, Precision, Recall, or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="ae26a-137">Klasyfikacja binarna Metryki klasy</span><span class="sxs-lookup"><span data-stu-id="ae26a-137">Binary Classification Metrics class</span></span>](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [<span data-ttu-id="ae26a-138">Relacja między krzywymi precision-recall i ROC</span><span class="sxs-lookup"><span data-stu-id="ae26a-138">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="evaluation-metrics-for-multi-class-classification"></a><span data-ttu-id="ae26a-139">Metryki oceny dla klasyfikacji wieloklasowej</span><span class="sxs-lookup"><span data-stu-id="ae26a-139">Evaluation metrics for Multi-class Classification</span></span>

| <span data-ttu-id="ae26a-140">Metryki</span><span class="sxs-lookup"><span data-stu-id="ae26a-140">Metrics</span></span>   |      <span data-ttu-id="ae26a-141">Opis</span><span class="sxs-lookup"><span data-stu-id="ae26a-141">Description</span></span>      |  <span data-ttu-id="ae26a-142">Szukać</span><span class="sxs-lookup"><span data-stu-id="ae26a-142">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="ae26a-143">**Mikrodokładność**</span><span class="sxs-lookup"><span data-stu-id="ae26a-143">**Micro-Accuracy**</span></span> |  <span data-ttu-id="ae26a-144">[Mikrośrednia dokładność](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) agreguje wkład y wszystkich klas, aby obliczyć średnią metrykę.</span><span class="sxs-lookup"><span data-stu-id="ae26a-144">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="ae26a-145">Jest to ułamek wystąpień przewidzianych poprawnie.</span><span class="sxs-lookup"><span data-stu-id="ae26a-145">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="ae26a-146">Mikrośrednia nie uwzględnia członkostwa w klasie.</span><span class="sxs-lookup"><span data-stu-id="ae26a-146">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="ae26a-147">Zasadniczo każda para klasy próbki przyczynia się w równym stopniu do metryki dokładności.</span><span class="sxs-lookup"><span data-stu-id="ae26a-147">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="ae26a-148">**Im bliżej 1.00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="ae26a-148">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="ae26a-149">W wieloklasowym zadaniu klasyfikacji mikrodokładność jest korzystna niż dokładność makro, jeśli podejrzewasz, że może istnieć nierównowaga klas (tj.</span><span class="sxs-lookup"><span data-stu-id="ae26a-149">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="ae26a-150">możesz mieć o wiele więcej przykładów jednej klasy niż innych klas).</span><span class="sxs-lookup"><span data-stu-id="ae26a-150">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="ae26a-151">**Dokładność makro**</span><span class="sxs-lookup"><span data-stu-id="ae26a-151">**Macro-Accuracy**</span></span> | <span data-ttu-id="ae26a-152">[Średnia dokładność makro](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) to średnia dokładność na poziomie klasy.</span><span class="sxs-lookup"><span data-stu-id="ae26a-152">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="ae26a-153">Dokładność dla każdej klasy jest obliczana, a dokładność makro jest średnią tych dokładności.</span><span class="sxs-lookup"><span data-stu-id="ae26a-153">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="ae26a-154">Zasadniczo każda klasa przyczynia się w równym stopniu do metryki dokładności.</span><span class="sxs-lookup"><span data-stu-id="ae26a-154">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="ae26a-155">Klasy mniejszościowe mają taką samą wagę jak większe klasy.</span><span class="sxs-lookup"><span data-stu-id="ae26a-155">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="ae26a-156">Metryka średniej makro daje taką samą wagę każdej klasie, niezależnie od liczby wystąpień z tej klasy, które zawiera zestaw danych.</span><span class="sxs-lookup"><span data-stu-id="ae26a-156">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="ae26a-157">**Im bliżej 1.00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="ae26a-157">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="ae26a-158">Oblicza metrykę niezależnie dla każdej klasy, a następnie przyjmuje średnią (w związku z tym traktując wszystkie klasy jednakowo)</span><span class="sxs-lookup"><span data-stu-id="ae26a-158">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="ae26a-159">**Utrata dziennika**</span><span class="sxs-lookup"><span data-stu-id="ae26a-159">**Log-loss**</span></span>| <span data-ttu-id="ae26a-160">[Strata logarytmiczny](http://wiki.fast.ai/index.php/Log_Loss) mierzy wydajność modelu klasyfikacji, gdzie dane wejściowe przewidywania jest wartość prawdopodobieństwa między 0,00 i 1,00.</span><span class="sxs-lookup"><span data-stu-id="ae26a-160">[Logarithmic loss](http://wiki.fast.ai/index.php/Log_Loss) measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="ae26a-161">Utrata dziennika zwiększa się, gdy przewidywane prawdopodobieństwo odbiega od rzeczywistej etykiety.</span><span class="sxs-lookup"><span data-stu-id="ae26a-161">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="ae26a-162">**Im bliżej 0,00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="ae26a-162">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="ae26a-163">Idealny model miałby utratę log-00.</span><span class="sxs-lookup"><span data-stu-id="ae26a-163">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="ae26a-164">Celem naszych modeli uczenia maszynowego jest zminimalizowanie tej wartości.</span><span class="sxs-lookup"><span data-stu-id="ae26a-164">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="ae26a-165">**Redukcja strat w logowaniu**</span><span class="sxs-lookup"><span data-stu-id="ae26a-165">**Log-Loss Reduction**</span></span> | <span data-ttu-id="ae26a-166">[Zmniejszenie strat logarytmicznych](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) można interpretować jako zaletę klasyfikatora nad przewidywanielos.</span><span class="sxs-lookup"><span data-stu-id="ae26a-166">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="ae26a-167">**Waha się od -inf i 1.00, gdzie 1.00 jest doskonałe prognozy i 0,00 wskazuje średnie prognozy**.</span><span class="sxs-lookup"><span data-stu-id="ae26a-167">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="ae26a-168">Na przykład, jeśli wartość jest równa 0,20, może być interpretowana jako "prawdopodobieństwo prawidłowego przewidywania jest o 20% lepsze niż przypadkowe zgadywanie"</span><span class="sxs-lookup"><span data-stu-id="ae26a-168">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="ae26a-169">Mikrodokładność jest na ogół lepiej dostosowana do potrzeb biznesowych prognoz ML.</span><span class="sxs-lookup"><span data-stu-id="ae26a-169">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="ae26a-170">Jeśli chcesz wybrać pojedynczą metrykę do wyboru jakości zadania klasyfikacji wieloklasowej, zazwyczaj powinna to być mikrodokładność.</span><span class="sxs-lookup"><span data-stu-id="ae26a-170">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="ae26a-171">Przykład, dla zadania klasyfikacji biletów pomocy technicznej: (mapy biletów przychodzących do zespołów pomocy technicznej)</span><span class="sxs-lookup"><span data-stu-id="ae26a-171">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="ae26a-172">Mikrodokładność - jak często bilet przychodzący jest klasyfikowany do właściwego zespołu?</span><span class="sxs-lookup"><span data-stu-id="ae26a-172">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="ae26a-173">Makrodokładność - dla przeciętnego zespołu, jak często bilet przychodzący jest poprawny dla ich drużyny?</span><span class="sxs-lookup"><span data-stu-id="ae26a-173">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="ae26a-174">Makrodokładność nadwagi małych zespołów w tym przykładzie; mały zespół, który dostaje tylko 10 biletów rocznie liczy się tak samo jak duży zespół z 10k biletów rocznie.</span><span class="sxs-lookup"><span data-stu-id="ae26a-174">Macro-accuracy overweights small teams in this example; a small team that gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="ae26a-175">Mikro-dokładność w tym przypadku lepiej koreluje z potrzebami biznesowymi, "ile czasu / pieniędzy firma może zaoszczędzić, automatyzując mój proces routingu biletów".</span><span class="sxs-lookup"><span data-stu-id="ae26a-175">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="ae26a-176">Aby uzyskać więcej informacji na temat metryki klasyfikacji wieloklasowej przeczytać następujące artykuły:</span><span class="sxs-lookup"><span data-stu-id="ae26a-176">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="ae26a-177">Mikro- i makro-średnia precyzji, przywołania i f-score</span><span class="sxs-lookup"><span data-stu-id="ae26a-177">Micro- and Macro-average of Precision, Recall, and F-Score</span></span>](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="ae26a-178">Klasyfikacja wieloklasowa z zestawem danych z nierównowagą</span><span class="sxs-lookup"><span data-stu-id="ae26a-178">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="evaluation-metrics-for-regression-and-recommendation"></a><span data-ttu-id="ae26a-179">Metryki oceny regresji i zalecenia</span><span class="sxs-lookup"><span data-stu-id="ae26a-179">Evaluation metrics for Regression and Recommendation</span></span>

<span data-ttu-id="ae26a-180">Zarówno regresji i zadania rekomendacji przewidzieć liczbę.</span><span class="sxs-lookup"><span data-stu-id="ae26a-180">Both the regression and recommendation tasks predict a number.</span></span> <span data-ttu-id="ae26a-181">W przypadku regresji liczba może być dowolną właściwością danych wyjściowych, na którą mają wpływ właściwości wejściowe.</span><span class="sxs-lookup"><span data-stu-id="ae26a-181">In the case of regression, the number can be any output property that is influenced by the input properties.</span></span> <span data-ttu-id="ae26a-182">Dla rekomendacji liczba ta jest zwykle wartością klasyfikacji (na przykład od 1 do 5) lub zaleceniem tak/nie (reprezentowanym odpowiednio przez 1 i 0).</span><span class="sxs-lookup"><span data-stu-id="ae26a-182">For recommendation, the number is usually a rating value (between 1 and 5 for example), or a yes/no recommendation (represented by 1 and 0 respectively).</span></span>

| <span data-ttu-id="ae26a-183">Metryka</span><span class="sxs-lookup"><span data-stu-id="ae26a-183">Metric</span></span>   |      <span data-ttu-id="ae26a-184">Opis</span><span class="sxs-lookup"><span data-stu-id="ae26a-184">Description</span></span>      |  <span data-ttu-id="ae26a-185">Szukać</span><span class="sxs-lookup"><span data-stu-id="ae26a-185">Look for</span></span> |
|----------|-----------------------|-----------|
| <span data-ttu-id="ae26a-186">**R-kwadrat**</span><span class="sxs-lookup"><span data-stu-id="ae26a-186">**R-Squared**</span></span> |  <span data-ttu-id="ae26a-187">[R-kwadrat (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination)lub *Współczynnik oznaczania* reprezentuje moc predykcyjną modelu jako wartość między -inf a 1,00.</span><span class="sxs-lookup"><span data-stu-id="ae26a-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="ae26a-188">1.00 oznacza, że jest idealne dopasowanie, a dopasowanie może być arbitralnie słabe, więc wyniki mogą być negatywne.</span><span class="sxs-lookup"><span data-stu-id="ae26a-188">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="ae26a-189">Wynik 0,00 oznacza, że model odgaduje oczekiwaną wartość etykiety.</span><span class="sxs-lookup"><span data-stu-id="ae26a-189">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="ae26a-190">R2 mierzy, jak blisko rzeczywistych wartości danych testowych są do przewidywanych wartości.</span><span class="sxs-lookup"><span data-stu-id="ae26a-190">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="ae26a-191">**Im bliżej 1,00, tym lepsza jakość**.</span><span class="sxs-lookup"><span data-stu-id="ae26a-191">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="ae26a-192">Jednak czasami niskie wartości R-kwadrat (takie jak 0,50) mogą być całkowicie normalne lub wystarczająco dobre dla scenariusza, a wysokie wartości r-kwadrat nie zawsze są dobre i podejrzane.</span><span class="sxs-lookup"><span data-stu-id="ae26a-192">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="ae26a-193">**Strata bezwzględna**</span><span class="sxs-lookup"><span data-stu-id="ae26a-193">**Absolute-loss**</span></span> |  <span data-ttu-id="ae26a-194">[Strata bezwzględna](https://en.wikipedia.org/wiki/Mean_absolute_error) lub *średni błąd bezwzględny (MAE)* mierzy, jak blisko są prognozy do rzeczywistych wyników.</span><span class="sxs-lookup"><span data-stu-id="ae26a-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="ae26a-195">Jest to średnia wszystkich błędów modelu, gdzie błąd modelu jest bezwzględną odległością między przewidywaną wartością etykiety a poprawną wartością etykiety.</span><span class="sxs-lookup"><span data-stu-id="ae26a-195">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="ae26a-196">Ten błąd przewidywania jest obliczany dla każdego rekordu zestawu danych testowych.</span><span class="sxs-lookup"><span data-stu-id="ae26a-196">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="ae26a-197">Na koniec średnia wartość jest obliczana dla wszystkich zarejestrowanych błędów bezwzględnych.</span><span class="sxs-lookup"><span data-stu-id="ae26a-197">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="ae26a-198">**Im bliżej 0,00, tym lepsza jakość.**</span><span class="sxs-lookup"><span data-stu-id="ae26a-198">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="ae26a-199">Średni błąd bezwzględny używa tej samej skali co mierzone dane (nie jest znormalizowany do określonego zakresu).</span><span class="sxs-lookup"><span data-stu-id="ae26a-199">The mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="ae26a-200">Strata bezwzględna, kwadratowa i strata rms mogą służyć tylko do porównywania modeli dla tego samego zestawu danych lub zestawu danych o podobnej dystrybucji wartości etykiety.</span><span class="sxs-lookup"><span data-stu-id="ae26a-200">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="ae26a-201">**Strata kwadratowa**</span><span class="sxs-lookup"><span data-stu-id="ae26a-201">**Squared-loss**</span></span> |  <span data-ttu-id="ae26a-202">[Kwadratowa strata](https://en.wikipedia.org/wiki/Mean_squared_error) lub *średni kwadratowy błąd (MSE),* zwany także *średnim odchyleniem kwadratowym (MSD),* informuje, jak blisko linii regresji jest zestaw wartości danych testowych, biorąc odległości od punktów do linii regresji (te odległości są błędy E) i kwadratury je.</span><span class="sxs-lookup"><span data-stu-id="ae26a-202">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="ae26a-203">Kwadratury dają większą wagę większym różnicom.</span><span class="sxs-lookup"><span data-stu-id="ae26a-203">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="ae26a-204">Zawsze jest nieujemna, a **wartości bliższe 0,00 są lepsze.**</span><span class="sxs-lookup"><span data-stu-id="ae26a-204">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="ae26a-205">W zależności od danych może być niemożliwe uzyskanie bardzo małej wartości dla średniego błędu kwadratowego.</span><span class="sxs-lookup"><span data-stu-id="ae26a-205">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="ae26a-206">**Utrata rms**</span><span class="sxs-lookup"><span data-stu-id="ae26a-206">**RMS-loss**</span></span> |  <span data-ttu-id="ae26a-207">[Strata RMS](https://en.wikipedia.org/wiki/Root-mean-square_deviation) lub *Średni błąd kwadratowy (RMSE)* (nazywany również *odchyleniem kwadratu głównego, RMSD),* mierzy różnicę między wartościami przewidywanymi przez model a wartościami obserwowanymi z modelowanego środowiska.</span><span class="sxs-lookup"><span data-stu-id="ae26a-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</span></span> <span data-ttu-id="ae26a-208">RMS-loss jest pierwiastek kwadratowy squared-loss i ma te same jednostki co etykieta, podobne do bezwzględnej utraty choć dając większą wagę do większych różnic.</span><span class="sxs-lookup"><span data-stu-id="ae26a-208">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="ae26a-209">Średni błąd kwadratowy katalogu głównego jest powszechnie używany w analizie klimatologii, prognozowania i regresji w celu zweryfikowania wyników eksperymentalnych.</span><span class="sxs-lookup"><span data-stu-id="ae26a-209">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="ae26a-210">Zawsze jest nieujemna, a **wartości bliższe 0,00 są lepsze.**</span><span class="sxs-lookup"><span data-stu-id="ae26a-210">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="ae26a-211">RMSD jest miarą dokładności, aby porównać błędy prognozowania różnych modeli dla określonego zestawu danych, a nie między zestawami danych, ponieważ jest zależny od skali.</span><span class="sxs-lookup"><span data-stu-id="ae26a-211">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="ae26a-212">Aby uzyskać więcej informacji na temat metryki regresji, przeczytaj następujące artykuły:</span><span class="sxs-lookup"><span data-stu-id="ae26a-212">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="ae26a-213">Analiza regresji: Jak interpretować R-squared i oceny dobroci-of-Fit?</span><span class="sxs-lookup"><span data-stu-id="ae26a-213">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="ae26a-214">Jak interpretować R-kwadrat w analizie regresji</span><span class="sxs-lookup"><span data-stu-id="ae26a-214">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="ae26a-215">Definicja R-kwadrat</span><span class="sxs-lookup"><span data-stu-id="ae26a-215">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="ae26a-216">Definicja średniego kwadratu błędu</span><span class="sxs-lookup"><span data-stu-id="ae26a-216">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="ae26a-217">Co to są średnie kwadratowe błąd i root średni kwadratbłędny błąd?</span><span class="sxs-lookup"><span data-stu-id="ae26a-217">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)

## <a name="evaluation-metrics-for-clustering"></a><span data-ttu-id="ae26a-218">Metryki oceny dla klastrowania</span><span class="sxs-lookup"><span data-stu-id="ae26a-218">Evaluation metrics for Clustering</span></span>

| <span data-ttu-id="ae26a-219">Metryka</span><span class="sxs-lookup"><span data-stu-id="ae26a-219">Metric</span></span>   |      <span data-ttu-id="ae26a-220">Opis</span><span class="sxs-lookup"><span data-stu-id="ae26a-220">Description</span></span>      |  <span data-ttu-id="ae26a-221">Szukać</span><span class="sxs-lookup"><span data-stu-id="ae26a-221">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="ae26a-222">**Średnia odległość**</span><span class="sxs-lookup"><span data-stu-id="ae26a-222">**Average Distance**</span></span>|<span data-ttu-id="ae26a-223">Średnia odległości między punktami danych a środkiem przypisanego klastra.</span><span class="sxs-lookup"><span data-stu-id="ae26a-223">Average of the distance between data points and the center of their assigned cluster.</span></span> <span data-ttu-id="ae26a-224">Średnia odległość jest miarą bliskości punktów danych do centroid klastra.</span><span class="sxs-lookup"><span data-stu-id="ae26a-224">The average distance is a measure of proximity of the data points to cluster centroids.</span></span> <span data-ttu-id="ae26a-225">Jest to miara tego, jak "ciasny" jest klaster.</span><span class="sxs-lookup"><span data-stu-id="ae26a-225">It's a measure of how 'tight' the cluster is.</span></span>|<span data-ttu-id="ae26a-226">Wartości bliższe **0** są lepsze.</span><span class="sxs-lookup"><span data-stu-id="ae26a-226">Values closer to **0** are better.</span></span> <span data-ttu-id="ae26a-227">Im bliżej zera jest średnia odległość, tym bardziej klastrowane są dane.</span><span class="sxs-lookup"><span data-stu-id="ae26a-227">The closer to zero the average distance is, the more clustered the data is.</span></span> <span data-ttu-id="ae26a-228">Należy jednak zauważyć, że ta metryka zmniejszy się, jeśli liczba klastrów zostanie zwiększona, a w skrajnym przypadku (gdzie każdy odrębny punkt danych jest jego własny klaster) będzie równa zero.</span><span class="sxs-lookup"><span data-stu-id="ae26a-228">Note though, that this metric will decrease if the number of clusters is increased, and in the extreme case (where each distinct data point is its own cluster) it will be equal to zero.</span></span>
|<span data-ttu-id="ae26a-229">**Indeks Daviesa Bouldina**</span><span class="sxs-lookup"><span data-stu-id="ae26a-229">**Davies Bouldin Index**</span></span>|<span data-ttu-id="ae26a-230">Średni stosunek odległości w obrębie klastra do odległości między klastrami.</span><span class="sxs-lookup"><span data-stu-id="ae26a-230">The average ratio of within-cluster distances to between-cluster distances.</span></span> <span data-ttu-id="ae26a-231">Im mocniej klastra i dalej od klastrów są, tym niższa jest ta wartość.</span><span class="sxs-lookup"><span data-stu-id="ae26a-231">The tighter the cluster, and the further apart the clusters are, the lower this value is.</span></span>|<span data-ttu-id="ae26a-232">Wartości bliższe **0** są lepsze.</span><span class="sxs-lookup"><span data-stu-id="ae26a-232">Values closer to **0** are better.</span></span> <span data-ttu-id="ae26a-233">Klastry, które są dalej od siebie i mniej rozproszone spowoduje lepszy wynik.</span><span class="sxs-lookup"><span data-stu-id="ae26a-233">Clusters that are farther apart and less dispersed will result in a better score.</span></span>|
|<span data-ttu-id="ae26a-234">**Znormalizowane wzajemne informacje**</span><span class="sxs-lookup"><span data-stu-id="ae26a-234">**Normalized Mutual Information**</span></span>|<span data-ttu-id="ae26a-235">Może być używany, gdy dane szkoleniowe używane do szkolenia modelu klastrowania również pochodzi z etykietprawdy ziemi (czyli nadzorowane klastrowania).</span><span class="sxs-lookup"><span data-stu-id="ae26a-235">Can be used when the training data used to train the clustering model also comes with ground truth labels (that is, supervised clustering).</span></span> <span data-ttu-id="ae26a-236">Metryka Znormalizowane wzajemne informacje mierzy, czy podobne punkty danych są przypisywane do tego samego klastra, a różne punkty danych są przypisywane do różnych klastrów.</span><span class="sxs-lookup"><span data-stu-id="ae26a-236">The Normalized Mutual Information metric measures whether similar data points get assigned to the same cluster and disparate data points get assigned to different clusters.</span></span> <span data-ttu-id="ae26a-237">Znormalizowane wzajemne informacje to wartość z wartością z rzędu 0–1</span><span class="sxs-lookup"><span data-stu-id="ae26a-237">Normalized mutual information is a value between 0 and 1</span></span>|<span data-ttu-id="ae26a-238">Wartości bliżej **1** są lepsze</span><span class="sxs-lookup"><span data-stu-id="ae26a-238">Values closer to **1** are better</span></span>|

## <a name="evaluation-metrics-for-ranking"></a><span data-ttu-id="ae26a-239">Wskaźniki oceny dla rankingu</span><span class="sxs-lookup"><span data-stu-id="ae26a-239">Evaluation metrics for Ranking</span></span>

| <span data-ttu-id="ae26a-240">Metryka</span><span class="sxs-lookup"><span data-stu-id="ae26a-240">Metric</span></span>   |      <span data-ttu-id="ae26a-241">Opis</span><span class="sxs-lookup"><span data-stu-id="ae26a-241">Description</span></span>      |  <span data-ttu-id="ae26a-242">Szukać</span><span class="sxs-lookup"><span data-stu-id="ae26a-242">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="ae26a-243">**Zdyskontowane skumulowane zyski**</span><span class="sxs-lookup"><span data-stu-id="ae26a-243">**Discounted Cumulative Gains**</span></span>|<span data-ttu-id="ae26a-244">Zdyskontowany zysk skumulowany (DCG) jest miarą jakości rankingu.</span><span class="sxs-lookup"><span data-stu-id="ae26a-244">Discounted cumulative gain (DCG) is a measure of ranking quality.</span></span> <span data-ttu-id="ae26a-245">Wynika to z dwóch założeń.</span><span class="sxs-lookup"><span data-stu-id="ae26a-245">It is derived from two assumptions.</span></span> <span data-ttu-id="ae26a-246">Po pierwsze: Bardzo istotne elementy są bardziej przydatne, gdy pojawiają się wyżej w kolejności rankingu.</span><span class="sxs-lookup"><span data-stu-id="ae26a-246">One: Highly relevant items are more useful when appearing higher in ranking order.</span></span> <span data-ttu-id="ae26a-247">Po drugie: Przydatność śledzi trafność, im większe znaczenie, tym bardziej przydatny element.</span><span class="sxs-lookup"><span data-stu-id="ae26a-247">Two: Usefulness tracks relevance that is, the higher the relevance, the more useful an item.</span></span> <span data-ttu-id="ae26a-248">Zdyskontowany zysk skumulowany jest obliczany dla określonej pozycji w kolejności.</span><span class="sxs-lookup"><span data-stu-id="ae26a-248">Discounted cumulative gain is calculated for a particular position in the ranking order.</span></span> <span data-ttu-id="ae26a-249">Podsumowuje klasyfikację istotności podzieloną przez logarytm indeksu rankingowego do pozycji zainteresowania.</span><span class="sxs-lookup"><span data-stu-id="ae26a-249">It sums the relevance grading divided by the logarithm of the ranking index up to the position of interest.</span></span> <span data-ttu-id="ae26a-250">Jest on obliczany przy użyciu $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Sklasyfikowania istotności są dostarczane do algorytmu szkolenia rankingowego jako etykiety prawdy naziemnej.</span><span class="sxs-lookup"><span data-stu-id="ae26a-250">It is calculated using $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Relevance gradings are provided to a ranking training algorithm as ground truth labels.</span></span> <span data-ttu-id="ae26a-251">Dla każdej pozycji w tabeli rankingowej znajduje się jedna wartość DCG, stąd nazwa Zdyskontowane **zyski**skumulowane .</span><span class="sxs-lookup"><span data-stu-id="ae26a-251">One DCG value is provided for each position in the ranking table, hence the name Discounted Cumulative **Gains**.</span></span> |<span data-ttu-id="ae26a-252">**Wyższe wartości są lepsze**</span><span class="sxs-lookup"><span data-stu-id="ae26a-252">**Higher values are better**</span></span>|
|<span data-ttu-id="ae26a-253">**Znormalizowane zdyskontowane zyski skumulowane**</span><span class="sxs-lookup"><span data-stu-id="ae26a-253">**Normalized Discounted Cumulative Gains**</span></span>|<span data-ttu-id="ae26a-254">Normalizacja DCG umożliwia porównywanie metryki dla list rankingowych o różnych długościach</span><span class="sxs-lookup"><span data-stu-id="ae26a-254">Normalizing DCG allows the metric to be compared for ranking lists of different lengths</span></span>|<span data-ttu-id="ae26a-255">**Wartości bliżej 1 są lepsze**</span><span class="sxs-lookup"><span data-stu-id="ae26a-255">**Values closer to 1 are better**</span></span>|

## <a name="evaluation-metrics-for-anomaly-detection"></a><span data-ttu-id="ae26a-256">Metryki oceny dla wykrywania anomalii</span><span class="sxs-lookup"><span data-stu-id="ae26a-256">Evaluation metrics for Anomaly Detection</span></span>

| <span data-ttu-id="ae26a-257">Metryka</span><span class="sxs-lookup"><span data-stu-id="ae26a-257">Metric</span></span>   |      <span data-ttu-id="ae26a-258">Opis</span><span class="sxs-lookup"><span data-stu-id="ae26a-258">Description</span></span>      |  <span data-ttu-id="ae26a-259">Szukać</span><span class="sxs-lookup"><span data-stu-id="ae26a-259">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="ae26a-260">**Obszar pod krzywą ROC**</span><span class="sxs-lookup"><span data-stu-id="ae26a-260">**Area Under ROC Curve**</span></span>|<span data-ttu-id="ae26a-261">Obszar pod krzywą operatora odbiornika mierzy, jak dobrze model oddziela nietypowe i zwykłe punkty danych.</span><span class="sxs-lookup"><span data-stu-id="ae26a-261">Area under the receiver operator curve measures how well the model separates anomalous and usual data points.</span></span>|<span data-ttu-id="ae26a-262">**Wartości bliżej 1 są lepsze**.</span><span class="sxs-lookup"><span data-stu-id="ae26a-262">**Values closer to 1 are better**.</span></span> <span data-ttu-id="ae26a-263">Tylko wartości większe niż 0,5 wykazują skuteczność modelu.</span><span class="sxs-lookup"><span data-stu-id="ae26a-263">Only values greater than 0.5 demonstrate effectiveness of the model.</span></span> <span data-ttu-id="ae26a-264">Wartości 0,5 lub niższe wskazują, że model nie jest lepszy niż losowo przydzielanie danych wejściowych do nietypowych i zwykłych kategorii</span><span class="sxs-lookup"><span data-stu-id="ae26a-264">Values of 0.5 or below indicate that the model is no better than randomly allocating the inputs to anomalous and usual categories</span></span>|
|<span data-ttu-id="ae26a-265">**Wskaźnik wykrywania przy liczbie fałszywych alarmów**</span><span class="sxs-lookup"><span data-stu-id="ae26a-265">**Detection Rate At False Positive Count**</span></span>|<span data-ttu-id="ae26a-266">Wskaźnik wykrywalności przy liczbie fałszywych alarmów jest stosunkiem liczby poprawnie zidentyfikowanych anomalii do całkowitej liczby anomalii w zestawie testów, indeksowanych przez każdy fałszywy alarm.</span><span class="sxs-lookup"><span data-stu-id="ae26a-266">Detection rate at false positive count is the ratio of the number of correctly identified anomalies to the total number of anomalies in a test set, indexed by each false positive.</span></span> <span data-ttu-id="ae26a-267">Oznacza to, że istnieje wartość dla wskaźnika wykrywania z fałszywie dodatnią liczbą dla każdego elementu fałszywie dodatniego.</span><span class="sxs-lookup"><span data-stu-id="ae26a-267">That is, there is a value for detection rate at false positive count for each false positive item.</span></span>|<span data-ttu-id="ae26a-268">**Wartości bliżej 1 są lepsze**.</span><span class="sxs-lookup"><span data-stu-id="ae26a-268">**Values closer to 1 are better**.</span></span> <span data-ttu-id="ae26a-269">Jeśli nie ma fałszywych alarmów, wartość ta wynosi 1</span><span class="sxs-lookup"><span data-stu-id="ae26a-269">If there are no false positives, then this value is 1</span></span>|

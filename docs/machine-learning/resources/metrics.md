---
title: Metryki ML.NET
description: Informacje o metrykach, które są używane do oceny wydajności modelu ML.NET
ms.date: 12/17/2019
ms.openlocfilehash: 8e823fd8cc344c1b8e0ecd709b527137368cbfa0
ms.sourcegitcommit: 9a97c76e141333394676bc5d264c6624b6f45bcf
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 01/08/2020
ms.locfileid: "75739605"
---
# <a name="evaluate-your-mlnet-model-with-metrics"></a><span data-ttu-id="8d03e-103">Oceń model ML.NET przy użyciu metryk</span><span class="sxs-lookup"><span data-stu-id="8d03e-103">Evaluate your ML.NET model with metrics</span></span>

<span data-ttu-id="8d03e-104">Informacje o metrykach używanych do szacowania modelu ML.NET.</span><span class="sxs-lookup"><span data-stu-id="8d03e-104">Understand the metrics used to evaluate an ML.NET model.</span></span>

<span data-ttu-id="8d03e-105">Metryki oceny są specyficzne dla typu zadania uczenia maszynowego wykonywanego przez model.</span><span class="sxs-lookup"><span data-stu-id="8d03e-105">Evaluation metrics are specific to the type of machine learning task that a model performs.</span></span>

<span data-ttu-id="8d03e-106">Na przykład dla zadania klasyfikacji model jest oceniany przez zmierzenie, jak dobrze przewidywalna kategoria jest zgodna z rzeczywistą kategorią.</span><span class="sxs-lookup"><span data-stu-id="8d03e-106">For example, for the classification task, the model is evaluated by measuring how well a predicted category matches the actual category.</span></span> <span data-ttu-id="8d03e-107">W przypadku klastrowania obliczenia opierają się na tym, jak zamykane elementy klastrowane są ze sobą i ile jest rozbarwień między klastrami.</span><span class="sxs-lookup"><span data-stu-id="8d03e-107">And for clustering, evaluation is based on how close clustered items are to each other, and how much separation there is between the clusters.</span></span>

## <a name="evaluation-metrics-for-binary-classification"></a><span data-ttu-id="8d03e-108">Metryki oceny dla klasyfikacji binarnej</span><span class="sxs-lookup"><span data-stu-id="8d03e-108">Evaluation metrics for Binary Classification</span></span>

| <span data-ttu-id="8d03e-109">Metryki</span><span class="sxs-lookup"><span data-stu-id="8d03e-109">Metrics</span></span>   |      <span data-ttu-id="8d03e-110">Opis</span><span class="sxs-lookup"><span data-stu-id="8d03e-110">Description</span></span>      |  <span data-ttu-id="8d03e-111">Wyszukaj</span><span class="sxs-lookup"><span data-stu-id="8d03e-111">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="8d03e-112">**Accuracy**</span><span class="sxs-lookup"><span data-stu-id="8d03e-112">**Accuracy**</span></span> |  <span data-ttu-id="8d03e-113">[Dokładność](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) jest proporcją prawidłowych prognoz z zestawem danych testowych.</span><span class="sxs-lookup"><span data-stu-id="8d03e-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="8d03e-114">Jest to stosunek liczby poprawnych prognoz do całkowitej liczby próbek wejściowych.</span><span class="sxs-lookup"><span data-stu-id="8d03e-114">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="8d03e-115">Działa dobrze, jeśli istnieje podobna liczba próbek należących do każdej klasy.</span><span class="sxs-lookup"><span data-stu-id="8d03e-115">It works well if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="8d03e-116">**Im bliżej 1,00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="8d03e-116">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="8d03e-117">Ale dokładnie 1,00 wskazuje na problem (często: wyciek etykiet/obiektu docelowego, nadmierne dopasowanie lub testowanie przy użyciu danych szkoleniowych).</span><span class="sxs-lookup"><span data-stu-id="8d03e-117">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="8d03e-118">Gdy dane testowe są niezrównoważone (gdy większość wystąpień należy do jednej z klas), zestaw danych jest mały lub wyniki zbliżają się do 0,00 lub 1,00, a dokładność nie przechwytuje skuteczności klasyfikatora i należy sprawdzić dodatkowe metryki.</span><span class="sxs-lookup"><span data-stu-id="8d03e-118">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is small, or scores approach 0.00 or 1.00, then accuracy doesn’t really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="8d03e-119">**AUC**</span><span class="sxs-lookup"><span data-stu-id="8d03e-119">**AUC**</span></span> |    <span data-ttu-id="8d03e-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) lub *obszar pod krzywą* mierzy obszar pod krzywą utworzoną przez wyczyszczenie prawdziwej dodatniej stawki w porównaniu z fałszywą dodatnią częstotliwością.</span><span class="sxs-lookup"><span data-stu-id="8d03e-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve* measures the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="8d03e-121">**Im bliżej 1,00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="8d03e-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="8d03e-122">Aby model mógł zostać akceptowalny, powinien być większy niż 0,50.</span><span class="sxs-lookup"><span data-stu-id="8d03e-122">It should be greater than 0.50 for a model to be acceptable.</span></span> <span data-ttu-id="8d03e-123">Model z AUCem 0,50 lub mniej to bezwartościowe.</span><span class="sxs-lookup"><span data-stu-id="8d03e-123">A model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="8d03e-124">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="8d03e-124">**AUCPR**</span></span> | <span data-ttu-id="8d03e-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) lub *obszar pod krzywą krzywej odwołania z dokładnością*: użyteczna miara sukcesu w przypadku, gdy klasy są niezrównoważone (zestawy danych o wysokim stopniu skośnym).</span><span class="sxs-lookup"><span data-stu-id="8d03e-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="8d03e-126">**Im bliżej 1,00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="8d03e-126">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="8d03e-127">Wysokie wyniki zbliżone do 1,00 pokazują, że klasyfikator zwraca dokładne wyniki (wysoka precyzja), a także zwraca większość pozytywnych wyników (wysoki stopień odwołania).</span><span class="sxs-lookup"><span data-stu-id="8d03e-127">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="8d03e-128">**F1-Score**</span><span class="sxs-lookup"><span data-stu-id="8d03e-128">**F1-score**</span></span> | <span data-ttu-id="8d03e-129">[Wynik F1](https://en.wikipedia.org/wiki/F1_score) jest znany również jako współczynnik *f-Score lub f-Measure*.</span><span class="sxs-lookup"><span data-stu-id="8d03e-129">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="8d03e-130">Jest to średnia harmoniczna precyzji i odwołania.</span><span class="sxs-lookup"><span data-stu-id="8d03e-130">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="8d03e-131">Wynik F1 jest przydatny, gdy chcesz uzyskać równowagę między dokładnością a odwołaniem.</span><span class="sxs-lookup"><span data-stu-id="8d03e-131">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="8d03e-132">**Im bliżej 1,00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="8d03e-132">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="8d03e-133">Wynik F1 osiąga swoją najlepszą wartość w 1,00 i najgorszy wynik o godzinie 0,00.</span><span class="sxs-lookup"><span data-stu-id="8d03e-133">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="8d03e-134">Informuje o tym, jak precyzyjnym klasyfikatorem jest.</span><span class="sxs-lookup"><span data-stu-id="8d03e-134">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="8d03e-135">Aby uzyskać więcej informacji na temat metryk klasyfikacji danych binarnych, przeczytaj następujące artykuły:</span><span class="sxs-lookup"><span data-stu-id="8d03e-135">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="8d03e-136">Dokładność, precyzja, odwołanie lub F1?</span><span class="sxs-lookup"><span data-stu-id="8d03e-136">Accuracy, Precision, Recall, or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="8d03e-137">Klasa metryk klasyfikacji binarnej</span><span class="sxs-lookup"><span data-stu-id="8d03e-137">Binary Classification Metrics class</span></span>](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [<span data-ttu-id="8d03e-138">Relacja między krzywą precyzji i odwołania ROC</span><span class="sxs-lookup"><span data-stu-id="8d03e-138">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="evaluation-metrics-for-multi-class-classification"></a><span data-ttu-id="8d03e-139">Metryki oceny dla klasyfikacji wieloklasowej</span><span class="sxs-lookup"><span data-stu-id="8d03e-139">Evaluation metrics for Multi-class Classification</span></span>

| <span data-ttu-id="8d03e-140">Metryki</span><span class="sxs-lookup"><span data-stu-id="8d03e-140">Metrics</span></span>   |      <span data-ttu-id="8d03e-141">Opis</span><span class="sxs-lookup"><span data-stu-id="8d03e-141">Description</span></span>      |  <span data-ttu-id="8d03e-142">Wyszukaj</span><span class="sxs-lookup"><span data-stu-id="8d03e-142">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="8d03e-143">**Mikro-dokładność**</span><span class="sxs-lookup"><span data-stu-id="8d03e-143">**Micro-Accuracy**</span></span> |  <span data-ttu-id="8d03e-144">Większość [średniej dokładności](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) agreguje wkłady wszystkich klas do obliczenia metryki średniej.</span><span class="sxs-lookup"><span data-stu-id="8d03e-144">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="8d03e-145">Jest to ułamek przewidziany prawidłowo.</span><span class="sxs-lookup"><span data-stu-id="8d03e-145">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="8d03e-146">Mikrośrednia nie przyjmuje przynależność klasy do konta.</span><span class="sxs-lookup"><span data-stu-id="8d03e-146">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="8d03e-147">Zasadniczo każda para klasy próbek przyczynia się równie do metryki dokładności.</span><span class="sxs-lookup"><span data-stu-id="8d03e-147">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="8d03e-148">**Im bliżej 1,00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="8d03e-148">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="8d03e-149">W zadaniu klasyfikacji wieloklasowej większość dokładności jest preferowana w porównaniu z dokładnością makr, jeśli podejrzewasz, że może to spowodować Niezrównoważenie klasy (tj.</span><span class="sxs-lookup"><span data-stu-id="8d03e-149">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="8d03e-150">może istnieć wiele więcej przykładów jednej klasy niż w przypadku innych klas).</span><span class="sxs-lookup"><span data-stu-id="8d03e-150">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="8d03e-151">**Dokładność makra**</span><span class="sxs-lookup"><span data-stu-id="8d03e-151">**Macro-Accuracy**</span></span> | <span data-ttu-id="8d03e-152">[Dokładność makra](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) jest średnią dokładnością na poziomie klasy.</span><span class="sxs-lookup"><span data-stu-id="8d03e-152">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="8d03e-153">Jest obliczana dokładność dla każdej klasy, a dokładność makr jest średnią z tych dokładności.</span><span class="sxs-lookup"><span data-stu-id="8d03e-153">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="8d03e-154">Zasadniczo każda klasa przyczynia się równie do metryki dokładności.</span><span class="sxs-lookup"><span data-stu-id="8d03e-154">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="8d03e-155">Klasy mniejszości są traktowane jako takie same wagi jak większe klasy.</span><span class="sxs-lookup"><span data-stu-id="8d03e-155">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="8d03e-156">Metryka średnia makro zapewnia taką samą wagę dla każdej klasy, niezależnie od liczby wystąpień tej klasy, w której znajduje się zestaw danych.</span><span class="sxs-lookup"><span data-stu-id="8d03e-156">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="8d03e-157">**Im bliżej 1,00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="8d03e-157">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="8d03e-158">Oblicza metrykę niezależnie dla każdej klasy, a następnie pobiera średnią (dlatego jednocześnie traktowanie wszystkich klas)</span><span class="sxs-lookup"><span data-stu-id="8d03e-158">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="8d03e-159">**Dziennik — utrata**</span><span class="sxs-lookup"><span data-stu-id="8d03e-159">**Log-loss**</span></span>| <span data-ttu-id="8d03e-160">[Strata logarytmiczna](http://wiki.fast.ai/index.php/Log_Loss) mierzy wydajność modelu klasyfikacji, gdzie dane wejściowe przewidywania to wartość prawdopodobieństwa z zakresu od 0,00 do 1,00.</span><span class="sxs-lookup"><span data-stu-id="8d03e-160">[Logarithmic loss](http://wiki.fast.ai/index.php/Log_Loss) measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="8d03e-161">Utrata strat dziennika zwiększa się, ponieważ przewidywane prawdopodobieństwo rozbieżności od rzeczywistej etykiety.</span><span class="sxs-lookup"><span data-stu-id="8d03e-161">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="8d03e-162">**Im bliżej 0,00, tym lepiej**.</span><span class="sxs-lookup"><span data-stu-id="8d03e-162">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="8d03e-163">Idealnym modelem będzie utratę dziennika 0,00.</span><span class="sxs-lookup"><span data-stu-id="8d03e-163">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="8d03e-164">Celem naszych modeli uczenia maszynowego jest zminimalizowanie tej wartości.</span><span class="sxs-lookup"><span data-stu-id="8d03e-164">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="8d03e-165">**Zmniejszenie utraty dziennika**</span><span class="sxs-lookup"><span data-stu-id="8d03e-165">**Log-Loss Reduction**</span></span> | <span data-ttu-id="8d03e-166">[Obniżenie strat w postaci logarytmu](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) można interpretować jako zalety klasyfikatora w przypadku prognoz losowych.</span><span class="sxs-lookup"><span data-stu-id="8d03e-166">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="8d03e-167">**Zakresy od-inf i 1,00, gdzie 1,00 są idealnymi przewidywaniami, a 0,00 wskazuje na średnie przewidywania**.</span><span class="sxs-lookup"><span data-stu-id="8d03e-167">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="8d03e-168">Na przykład jeśli wartość jest równa 0,20, może być interpretowana jako "prawdopodobieństwo poprawnego przewidywania jest 20% lepsze niż losowe zgadywanie"</span><span class="sxs-lookup"><span data-stu-id="8d03e-168">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="8d03e-169">Większość dokładności jest ogólnie lepsza w zakresie potrzeb firmy dla przewidywania ML.</span><span class="sxs-lookup"><span data-stu-id="8d03e-169">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="8d03e-170">Jeśli chcesz wybrać jedną metrykę w celu wybrania jakości zadania klasyfikacji wieloklasowej, powinna ona być zwykle z mikrodokładnością.</span><span class="sxs-lookup"><span data-stu-id="8d03e-170">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="8d03e-171">Przykład dla zadania klasyfikacji biletów pomocy technicznej: (mapuje bilety przychodzące do obsługi zespołów)</span><span class="sxs-lookup"><span data-stu-id="8d03e-171">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="8d03e-172">Mikro-dokładność — jak często bilet przychodzący jest klasyfikowany do właściwego zespołu?</span><span class="sxs-lookup"><span data-stu-id="8d03e-172">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="8d03e-173">Dokładność makro — w przypadku średniego zespołu, jak często bilet przychodzący jest poprawny dla swojego zespołu?</span><span class="sxs-lookup"><span data-stu-id="8d03e-173">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="8d03e-174">Dokładność makr umożliwia przeważnie rozważenia małych zespołów w tym przykładzie. mały zespół, który pobiera tylko 10 biletów na rok, tak samo, jak duży zespół z 10 biletami rocznie.</span><span class="sxs-lookup"><span data-stu-id="8d03e-174">Macro-accuracy overweights small teams in this example; a small team that gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="8d03e-175">Większość dokładności w tym przypadku jest bardziej skorelowana z potrzebami biznesowymi, "ile czasu/pieniędzy może zaoszczędzić firma, automatyzując proces routingu biletów".</span><span class="sxs-lookup"><span data-stu-id="8d03e-175">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="8d03e-176">Aby uzyskać więcej informacji na temat metryk klasyfikacji wieloklasowej, przeczytaj następujące artykuły:</span><span class="sxs-lookup"><span data-stu-id="8d03e-176">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="8d03e-177">Funkcja mikro-and-Average z dokładnością, odwołaniem i wynikiem F-Score</span><span class="sxs-lookup"><span data-stu-id="8d03e-177">Micro- and Macro-average of Precision, Recall, and F-Score</span></span>](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="8d03e-178">Klasyfikacja wieloklasowa z niezrównoważonym zestawem danych</span><span class="sxs-lookup"><span data-stu-id="8d03e-178">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="evaluation-metrics-for-regression-and-recommendation"></a><span data-ttu-id="8d03e-179">Metryki oceny dla regresji i rekomendacji</span><span class="sxs-lookup"><span data-stu-id="8d03e-179">Evaluation metrics for Regression and Recommendation</span></span>

<span data-ttu-id="8d03e-180">Zadania regresji i rekomendacji przewidują liczbę.</span><span class="sxs-lookup"><span data-stu-id="8d03e-180">Both the regression and recommendation tasks predict a number.</span></span> <span data-ttu-id="8d03e-181">W przypadku regresji liczba może być dowolną właściwością wyjściową, która ma wpływ na właściwości wejściowe.</span><span class="sxs-lookup"><span data-stu-id="8d03e-181">In the case of regression, the number can be any output property that is influenced by the input properties.</span></span> <span data-ttu-id="8d03e-182">W przypadku rekomendacji liczba jest zwykle wartością klasyfikacji (na przykład z zakresu od 1 do 5) lub zaleceniem tak/nie (reprezentowanym odpowiednio przez 1 i 0).</span><span class="sxs-lookup"><span data-stu-id="8d03e-182">For recommendation, the number is usually a rating value (between 1 and 5 for example), or a yes/no recommendation (represented by 1 and 0 respectively).</span></span>

| <span data-ttu-id="8d03e-183">Metryki</span><span class="sxs-lookup"><span data-stu-id="8d03e-183">Metric</span></span>   |      <span data-ttu-id="8d03e-184">Opis</span><span class="sxs-lookup"><span data-stu-id="8d03e-184">Description</span></span>      |  <span data-ttu-id="8d03e-185">Wyszukaj</span><span class="sxs-lookup"><span data-stu-id="8d03e-185">Look for</span></span> |
|----------|-----------------------|-----------|
| <span data-ttu-id="8d03e-186">**R-kwadratowy**</span><span class="sxs-lookup"><span data-stu-id="8d03e-186">**R-Squared**</span></span> |  <span data-ttu-id="8d03e-187">Oznaczenie [R-kwadratowe (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination)lub *współczynnik wyznaczania* reprezentuje potęgę modelu jako wartość z przedziału od-inf do 1,00.</span><span class="sxs-lookup"><span data-stu-id="8d03e-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="8d03e-188">1,00 oznacza, że istnieje idealne dopasowanie, a dopasowanie może być niezadowalające, aby wyniki mogły być ujemne.</span><span class="sxs-lookup"><span data-stu-id="8d03e-188">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="8d03e-189">Wynik 0,00 oznacza, że model zgadywaniu oczekiwanej wartości dla etykiety.</span><span class="sxs-lookup"><span data-stu-id="8d03e-189">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="8d03e-190">R2 mierzy, jak zamknąć rzeczywiste wartości danych testowych do wartości przewidywanych.</span><span class="sxs-lookup"><span data-stu-id="8d03e-190">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="8d03e-191">**Im bliżej 1,00, tym lepsza jakość**.</span><span class="sxs-lookup"><span data-stu-id="8d03e-191">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="8d03e-192">Niemniej jednak czasami małe wartości (na przykład 0,50) mogą być całkowicie normalne lub wystarczające dla danego scenariusza, a wysokie wartości R-kwadrat nie zawsze są dobre i są podejrzane.</span><span class="sxs-lookup"><span data-stu-id="8d03e-192">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="8d03e-193">**Bezwzględna utrata**</span><span class="sxs-lookup"><span data-stu-id="8d03e-193">**Absolute-loss**</span></span> |  <span data-ttu-id="8d03e-194">[Bezwzględne](https://en.wikipedia.org/wiki/Mean_absolute_error) lub *średnie bezwzględne błędy (Mae)* mierzą, jak blisko prognoz są rzeczywiste wyniki.</span><span class="sxs-lookup"><span data-stu-id="8d03e-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="8d03e-195">Jest to średnia ze wszystkich błędów modelu, gdzie błąd modelu to bezwzględna odległość między przewidywalną wartością etykiety a poprawną wartością etykiety.</span><span class="sxs-lookup"><span data-stu-id="8d03e-195">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="8d03e-196">Ten błąd przewidywania jest obliczany dla każdego rekordu zestawu danych testowych.</span><span class="sxs-lookup"><span data-stu-id="8d03e-196">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="8d03e-197">Na koniec wartość średnia jest obliczana dla wszystkich zarejestrowanych błędów bezwzględnych.</span><span class="sxs-lookup"><span data-stu-id="8d03e-197">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="8d03e-198">**Im bliżej 0,00, tym lepsza jakość.**</span><span class="sxs-lookup"><span data-stu-id="8d03e-198">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="8d03e-199">Średni błąd bezwzględny używa takiej samej skali, jak dane są mierzone (nie jest znormalizowany do określonego zakresu).</span><span class="sxs-lookup"><span data-stu-id="8d03e-199">The mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="8d03e-200">Bezwzględne, kwadratowe straty i straty RMS mogą być używane tylko w celu porównania między modelami dla tego samego zestawu danych lub zestawu danych o podobnym rozkładzie wartości etykiety.</span><span class="sxs-lookup"><span data-stu-id="8d03e-200">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="8d03e-201">**Kwadratowa strata**</span><span class="sxs-lookup"><span data-stu-id="8d03e-201">**Squared-loss**</span></span> |  <span data-ttu-id="8d03e-202">[Kwadratowy](https://en.wikipedia.org/wiki/Mean_squared_error) lub średni kwadratowy *błąd (MSE)* , nazywany również *średnim odchyleniem kwadratowym (MSD)* , informuje o tym, jak zamykasz linię regresji do zestawu wartości danych testowych, przenosząc odległości od punktów do linii regresji (te odległości są błędy E) i podniesienie je.</span><span class="sxs-lookup"><span data-stu-id="8d03e-202">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="8d03e-203">Podniesienie zwiększa wagę do większych różnic.</span><span class="sxs-lookup"><span data-stu-id="8d03e-203">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="8d03e-204">Jest on zawsze nieujemny, a **wartości zbliżone do 0,00 są lepsze**.</span><span class="sxs-lookup"><span data-stu-id="8d03e-204">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="8d03e-205">W zależności od danych może być niemożliwe uzyskanie bardzo małej wartości dla średniego błędu.</span><span class="sxs-lookup"><span data-stu-id="8d03e-205">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="8d03e-206">**RMS — utrata**</span><span class="sxs-lookup"><span data-stu-id="8d03e-206">**RMS-loss**</span></span> |  <span data-ttu-id="8d03e-207">Funkcja [RMS — utrata](https://en.wikipedia.org/wiki/Root-mean-square_deviation) lub *główna średnia kwadratowa błąd (RMSE)* (zwane także " *odchyleniem kwadratowym średniej", RMSD*), mierzy różnicę między wartościami przewidywanymi przez model i wartościami zaobserwowanymi ze środowiska, które jest modelowane.</span><span class="sxs-lookup"><span data-stu-id="8d03e-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</span></span> <span data-ttu-id="8d03e-208">RMS-strata to pierwiastek kwadratowy z kwadratową stratą i ma te same jednostki, jak etykieta, podobnie jak w przypadku utraty absolutnej, dzięki czemu bardziej ważniejsze są większe różnice.</span><span class="sxs-lookup"><span data-stu-id="8d03e-208">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="8d03e-209">Główny błąd średniego kwadratu jest często używany w analizie climatology, prognozowania i regresji w celu sprawdzenia doświadczalnych wyników.</span><span class="sxs-lookup"><span data-stu-id="8d03e-209">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="8d03e-210">Jest on zawsze nieujemny, a **wartości zbliżone do 0,00 są lepsze**.</span><span class="sxs-lookup"><span data-stu-id="8d03e-210">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="8d03e-211">RMSD to miara dokładności, która umożliwia porównanie błędów prognozowania różnych modeli dla określonego zestawu danych, a nie między zbiorami, ponieważ jest zależne od skali.</span><span class="sxs-lookup"><span data-stu-id="8d03e-211">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="8d03e-212">Aby uzyskać więcej informacji na temat metryk regresji, przeczytaj następujące artykuły:</span><span class="sxs-lookup"><span data-stu-id="8d03e-212">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="8d03e-213">Analiza regresji: jak interpretować R-kwadrat i ocenić dobry stopień dopasowania?</span><span class="sxs-lookup"><span data-stu-id="8d03e-213">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="8d03e-214">Sposób interpretacji języka R-kwadratowego w analizie regresji</span><span class="sxs-lookup"><span data-stu-id="8d03e-214">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="8d03e-215">Definicja R-kwadratowa</span><span class="sxs-lookup"><span data-stu-id="8d03e-215">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="8d03e-216">Średnia kwadratowa definicja błędu</span><span class="sxs-lookup"><span data-stu-id="8d03e-216">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="8d03e-217">Co to jest błąd kwadratowy i główny błąd oznaczający pierwiastek?</span><span class="sxs-lookup"><span data-stu-id="8d03e-217">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)

## <a name="evaluation-metrics-for-clustering"></a><span data-ttu-id="8d03e-218">Metryki oceny dla klastra</span><span class="sxs-lookup"><span data-stu-id="8d03e-218">Evaluation metrics for Clustering</span></span>

| <span data-ttu-id="8d03e-219">Metryki</span><span class="sxs-lookup"><span data-stu-id="8d03e-219">Metric</span></span>   |      <span data-ttu-id="8d03e-220">Opis</span><span class="sxs-lookup"><span data-stu-id="8d03e-220">Description</span></span>      |  <span data-ttu-id="8d03e-221">Wyszukaj</span><span class="sxs-lookup"><span data-stu-id="8d03e-221">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="8d03e-222">**Średnia odległość**</span><span class="sxs-lookup"><span data-stu-id="8d03e-222">**Average Distance**</span></span>|<span data-ttu-id="8d03e-223">Średnia odległość między punktami danych a centrum przypisanego do niego klastra.</span><span class="sxs-lookup"><span data-stu-id="8d03e-223">Average of the distance between data points and the center of their assigned cluster.</span></span> <span data-ttu-id="8d03e-224">Średnia odległość to miara bliskości punktów danych do centroids klastra.</span><span class="sxs-lookup"><span data-stu-id="8d03e-224">The average distance is a measure of proximity of the data points to cluster centroids.</span></span> <span data-ttu-id="8d03e-225">Jest to miara, w jaki sposób "ciasne" klastra jest.</span><span class="sxs-lookup"><span data-stu-id="8d03e-225">It's a measure of how 'tight' the cluster is.</span></span>|<span data-ttu-id="8d03e-226">Wartości bliżej **0** są lepsze.</span><span class="sxs-lookup"><span data-stu-id="8d03e-226">Values closer to **0** are better.</span></span> <span data-ttu-id="8d03e-227">Im bliżej średniej wartości, tym bardziej klastrowane są dane.</span><span class="sxs-lookup"><span data-stu-id="8d03e-227">The closer to zero the average distance is, the more clustered the data is.</span></span> <span data-ttu-id="8d03e-228">Należy pamiętać, że ta Metryka zmniejszy się, jeśli liczba klastrów zostanie zwiększona, a w skrajnym przypadku (gdzie każdy odrębny punkt danych jest własnym klastrem) będzie równa zero.</span><span class="sxs-lookup"><span data-stu-id="8d03e-228">Note though, that this metric will decrease if the number of clusters is increased, and in the extreme case (where each distinct data point is its own cluster) it will be equal to zero.</span></span>
|<span data-ttu-id="8d03e-229">**Indeks Davies Bouldin**</span><span class="sxs-lookup"><span data-stu-id="8d03e-229">**Davies Bouldin Index**</span></span>|<span data-ttu-id="8d03e-230">Średni stosunek odległości między klastrami i między nimi.</span><span class="sxs-lookup"><span data-stu-id="8d03e-230">The average ratio of within-cluster distances to between-cluster distances.</span></span> <span data-ttu-id="8d03e-231">Im ściślejszy klaster, a inne klastry to, tym niższa wartość to.</span><span class="sxs-lookup"><span data-stu-id="8d03e-231">The tighter the cluster, and the further apart the clusters are, the lower this value is.</span></span>|<span data-ttu-id="8d03e-232">Wartości bliżej **0** są lepsze.</span><span class="sxs-lookup"><span data-stu-id="8d03e-232">Values closer to **0** are better.</span></span> <span data-ttu-id="8d03e-233">Klastry, które są dalej i mniej rozpraszane, spowodują lepszy wynik.</span><span class="sxs-lookup"><span data-stu-id="8d03e-233">Clusters that are farther apart and less dispersed will result in a better score.</span></span>|
|<span data-ttu-id="8d03e-234">**Znormalizowane informacje wzajemne**</span><span class="sxs-lookup"><span data-stu-id="8d03e-234">**Normalized Mutual Information**</span></span>|<span data-ttu-id="8d03e-235">Mogą być używane, gdy dane szkoleniowe używane do uczenia modelu klastrowania są również dostarczane z etykietami prawdy (czyli klastrowanie nadzorowane).</span><span class="sxs-lookup"><span data-stu-id="8d03e-235">Can be used when the training data used to train the clustering model also comes with ground truth labels (that is, supervised clustering).</span></span> <span data-ttu-id="8d03e-236">Znormalizowana Metryka informacji wzajemnych mierzy, czy podobne punkty danych są przypisane do tego samego klastra, a różne punkty danych są przypisane do różnych klastrów.</span><span class="sxs-lookup"><span data-stu-id="8d03e-236">The Normalized Mutual Information metric measures whether similar data points get assigned to the same cluster and disparate data points get assigned to different clusters.</span></span> <span data-ttu-id="8d03e-237">Znormalizowane informacje wzajemne to wartość z zakresu od 0 do 1</span><span class="sxs-lookup"><span data-stu-id="8d03e-237">Normalized mutual information is a value between 0 and 1</span></span>|<span data-ttu-id="8d03e-238">Wartości bliżej **1** są lepsze</span><span class="sxs-lookup"><span data-stu-id="8d03e-238">Values closer to **1** are better</span></span>|

## <a name="evaluation-metrics-for-ranking"></a><span data-ttu-id="8d03e-239">Metryki oceny na potrzeby klasyfikowania</span><span class="sxs-lookup"><span data-stu-id="8d03e-239">Evaluation metrics for Ranking</span></span>

| <span data-ttu-id="8d03e-240">Metryki</span><span class="sxs-lookup"><span data-stu-id="8d03e-240">Metric</span></span>   |      <span data-ttu-id="8d03e-241">Opis</span><span class="sxs-lookup"><span data-stu-id="8d03e-241">Description</span></span>      |  <span data-ttu-id="8d03e-242">Wyszukaj</span><span class="sxs-lookup"><span data-stu-id="8d03e-242">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="8d03e-243">**Obniżone zyski zbiorcze**</span><span class="sxs-lookup"><span data-stu-id="8d03e-243">**Discounted Cumulative Gains**</span></span>|<span data-ttu-id="8d03e-244">Rabat skumulowany (DCG) jest miarą jakości rankingu.</span><span class="sxs-lookup"><span data-stu-id="8d03e-244">Discounted cumulative gain (DCG) is a measure of ranking quality.</span></span> <span data-ttu-id="8d03e-245">Pochodzi ona z dwóch założeń.</span><span class="sxs-lookup"><span data-stu-id="8d03e-245">It is derived from two assumptions.</span></span> <span data-ttu-id="8d03e-246">Jeden: wysoce istotne elementy są bardziej przydatne, gdy pojawiają się wyższe w kolejności klasyfikacji.</span><span class="sxs-lookup"><span data-stu-id="8d03e-246">One: Highly relevant items are more useful when appearing higher in ranking order.</span></span> <span data-ttu-id="8d03e-247">Dwie: użyteczność śledzi istotność, im wyższa wartość istotności, tym bardziej użyteczny element.</span><span class="sxs-lookup"><span data-stu-id="8d03e-247">Two: Usefulness tracks relevance that is, the higher the relevance, the more useful an item.</span></span> <span data-ttu-id="8d03e-248">Łączny zysk z rabatem jest obliczany dla konkretnej pozycji w kolejności klasyfikacji.</span><span class="sxs-lookup"><span data-stu-id="8d03e-248">Discounted cumulative gain is calculated for a particular position in the ranking order.</span></span> <span data-ttu-id="8d03e-249">Sumuje ocenę przydatności podzieloną przez LOGARYTM indeksu klasyfikacji do pozycji zainteresowania.</span><span class="sxs-lookup"><span data-stu-id="8d03e-249">It sums the relevance grading divided by the logarithm of the ranking index up to the position of interest.</span></span> <span data-ttu-id="8d03e-250">Jest on obliczany przy użyciu $ \ sum_ {i = 0} ^ {p} \frac {rel_i} {\ log_ {e} {i + 1}} $ oceny przydatności są dostarczane do algorytmu szkoleniowego klasyfikacji jako etykiety prawdy.</span><span class="sxs-lookup"><span data-stu-id="8d03e-250">It is calculated using $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Relevance gradings are provided to a ranking training algorithm as ground truth labels.</span></span> <span data-ttu-id="8d03e-251">Jedna wartość DCG jest dostarczana dla każdej pozycji w tabeli klasyfikacji, dlatego nazwa otrzymuje **zyski**zbiorcze.</span><span class="sxs-lookup"><span data-stu-id="8d03e-251">One DCG value is provided for each position in the ranking table, hence the name Discounted Cumulative **Gains**.</span></span> |<span data-ttu-id="8d03e-252">**Wyższe wartości są lepsze**</span><span class="sxs-lookup"><span data-stu-id="8d03e-252">**Higher values are better**</span></span>|
|<span data-ttu-id="8d03e-253">**Znormalizowane zyski skumulowane z rabatem**</span><span class="sxs-lookup"><span data-stu-id="8d03e-253">**Normalized Discounted Cumulative Gains**</span></span>|<span data-ttu-id="8d03e-254">Normalizacja DCG umożliwia porównywanie metryk w przypadku list klasyfikacji o różnych długościach</span><span class="sxs-lookup"><span data-stu-id="8d03e-254">Normalizing DCG allows the metric to be compared for ranking lists of different lengths</span></span>|<span data-ttu-id="8d03e-255">**Wartości bliżej 1 są lepsze**</span><span class="sxs-lookup"><span data-stu-id="8d03e-255">**Values closer to 1 are better**</span></span>|

## <a name="evaluation-metrics-for-anomaly-detection"></a><span data-ttu-id="8d03e-256">Metryki oceny na potrzeby wykrywania anomalii</span><span class="sxs-lookup"><span data-stu-id="8d03e-256">Evaluation metrics for Anomaly Detection</span></span>

| <span data-ttu-id="8d03e-257">Metryki</span><span class="sxs-lookup"><span data-stu-id="8d03e-257">Metric</span></span>   |      <span data-ttu-id="8d03e-258">Opis</span><span class="sxs-lookup"><span data-stu-id="8d03e-258">Description</span></span>      |  <span data-ttu-id="8d03e-259">Wyszukaj</span><span class="sxs-lookup"><span data-stu-id="8d03e-259">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="8d03e-260">**Obszar pod krzywą ROC**</span><span class="sxs-lookup"><span data-stu-id="8d03e-260">**Area Under ROC Curve**</span></span>|<span data-ttu-id="8d03e-261">Obszar pod krzywą operatora odbiornika mierzy, jak dobrze model oddziela anomalie i zwykłe punkty danych.</span><span class="sxs-lookup"><span data-stu-id="8d03e-261">Area under the receiver operator curve measures how well the model separates anomalous and usual data points.</span></span>|<span data-ttu-id="8d03e-262">**Wartości bliżej 1 są lepsze**.</span><span class="sxs-lookup"><span data-stu-id="8d03e-262">**Values closer to 1 are better**.</span></span> <span data-ttu-id="8d03e-263">Tylko wartości większe niż 0,5 wykazują skuteczność modelu.</span><span class="sxs-lookup"><span data-stu-id="8d03e-263">Only values greater than 0.5 demonstrate effectiveness of the model.</span></span> <span data-ttu-id="8d03e-264">Wartości 0,5 lub poniżej wskazują, że model nie jest lepszy niż losowo przydzielać dane do anomalii i zwykłych kategorii</span><span class="sxs-lookup"><span data-stu-id="8d03e-264">Values of 0.5 or below indicate that the model is no better than randomly allocating the inputs to anomalous and usual categories</span></span>|
|<span data-ttu-id="8d03e-265">**Częstotliwość wykrywania z fałszywą liczbą dodatnią**</span><span class="sxs-lookup"><span data-stu-id="8d03e-265">**Detection Rate At False Positive Count**</span></span>|<span data-ttu-id="8d03e-266">Częstotliwość wykrycia z fałszywą liczbą dodatnią jest stosunkiem liczby prawidłowo zidentyfikowanych anomalii do całkowitej liczby anomalii w zestawie testów, indeksowanych przez każdy fałszywy wynik.</span><span class="sxs-lookup"><span data-stu-id="8d03e-266">Detection rate at false positive count is the ratio of the number of correctly identified anomalies to the total number of anomalies in a test set, indexed by each false positive.</span></span> <span data-ttu-id="8d03e-267">Oznacza to, że istnieje wartość współczynnika wykrycia z fałszywą liczbą dodatnią dla każdego elementu fałszywie dodatnich.</span><span class="sxs-lookup"><span data-stu-id="8d03e-267">That is, there is a value for detection rate at false positive count for each false positive item.</span></span>|<span data-ttu-id="8d03e-268">**Wartości bliżej 1 są lepsze**.</span><span class="sxs-lookup"><span data-stu-id="8d03e-268">**Values closer to 1 are better**.</span></span> <span data-ttu-id="8d03e-269">Jeśli nie ma żadnych fałszywie dodatnich, ta wartość jest równa 1</span><span class="sxs-lookup"><span data-stu-id="8d03e-269">If there are no false positives, then this value is 1</span></span>|
